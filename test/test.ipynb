{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-30T11:59:39.643816Z",
     "start_time": "2024-11-30T11:59:37.736766Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:01:06.316819Z",
     "start_time": "2024-11-30T12:01:03.519059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "MNIST 데이터세트를 로드하고 준비합니다. 샘플 데이터를 정수에서 부동 소수점 숫자로 변환합니다.\n",
    "\"\"\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ],
   "id": "c7a886204789558a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:01:20.092551Z",
     "start_time": "2024-11-30T12:01:20.027599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "층을 차례대로 쌓아 tf.keras.Sequential 모델을 만듭니다. 훈련에 사용할 옵티마이저(optimizer)와 손실 함수를 선택합니다:\n",
    "\"\"\"\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "89d3fe7aa265b3b5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:01:26.914955Z",
     "start_time": "2024-11-30T12:01:26.902892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "각 예시에서 모델은 각 클래스에 대해 하나씩, logits 또는 log-odds 스코어 벡터를 반환합니다.\n",
    "\"\"\"\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ],
   "id": "be5e93cb03a23c63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07920178, 0.12940672, 0.09074259, 0.08143337, 0.08310716,\n",
       "        0.12129363, 0.13972594, 0.12010849, 0.10762591, 0.04735447]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:07:09.255970Z",
     "start_time": "2024-11-30T12:07:09.251739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "tf.nn.softmax 함수는 다음과 같이 이러한 로짓을 각 클래스에 대한 확률로 변환합니다.\n",
    "참고: tf.nn.softmax 함수를 네트워크의 마지막 레이어에 대한 활성화 함수로 베이킹할 수 있습니다. 이렇게 하면 모델 출력을 더 직접적으로 해석할 수 있지만 이 접근법은 소프트맥스 출력을 사용할 경우 모든 모델에 대해 정확하고 수치적으로 안정적인 손실 계산을 제공하는 것이 불가능하므로 권장하지 않습니다.\n",
    "\"\"\"\n",
    "tf.nn.softmax(predictions).numpy()"
   ],
   "id": "ede42a3af950d626",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09790612, 0.10294697, 0.09904259, 0.09812485, 0.09828923,\n",
       "        0.10211514, 0.10401481, 0.10199419, 0.10072895, 0.0948372 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:01:40.105494Z",
     "start_time": "2024-11-30T12:01:40.103421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "losses.SparseCategoricalCrossentropy를 사용하여 로짓의 벡터와 True 인덱스를 사용하고 각 예시에 대해 스칼라 손실을 반환하는 훈련용 손실 함수를 정의합니다.\n",
    "\"\"\"\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ],
   "id": "78e460be6c1bfa76",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:01:45.549933Z",
     "start_time": "2024-11-30T12:01:45.539586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "이 손실은 실제 클래스의 음의 로그 확률과 같습니다. 모델이 올바른 클래스를 확신하는 경우 손실은 0입니다.\n",
    "\n",
    "이 훈련되지 않은 모델은 무작위에 가까운 확률(각 클래스에 대해 1/10)을 제공하므로 초기 손실은 -tf.math.log(1/10) ~= 2.3에 근접해야 합니다.\n",
    "\"\"\"\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ],
   "id": "15368e4ea7f12cb4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2816544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:01:50.531136Z",
     "start_time": "2024-11-30T12:01:50.525509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "훈련을 시작하기 전에 Keras Model.compile을 사용하여 모델을 구성하고 컴파일합니다. optimizer 클래스를 adam으로 설정하고 loss를 앞에서 정의한 loss_fn 함수로 설정합니다. metrics 매개변수를 accuracy로 설정하여 모델에 대해 평가할 메트릭을 지정합니다.\n",
    "\"\"\"\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ],
   "id": "e7c5bedb753883d7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:02:05.886223Z",
     "start_time": "2024-11-30T12:01:58.380426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "모델을 훈련하고 평가합니다:\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, epochs=5)"
   ],
   "id": "e22c93515110687d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 5:18 - loss: 2.2442 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 21:01:58.437123: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Users/cyj/miniconda3/envs/Tensorflow/lib/python3.11/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 759us/step - loss: 0.2989 - accuracy: 0.9136\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.1440 - accuracy: 0.9580\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.1071 - accuracy: 0.9673\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.0870 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.0729 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176349290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:02:26.378779Z",
     "start_time": "2024-11-30T12:02:18.207727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Model.evaluate 메서드는 일반적으로 \"Validation-set\" 또는 \"Test-set\"에서 모델 성능을 확인합니다.\n",
    "훈련된 이미지 분류기는 이 데이터셋에서 약 98%의 정확도를 달성합니다. 더 자세한 내용은 TensorFlow 튜토리얼을 참고하세요.\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ],
   "id": "e2d6430de4b34baa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 867us/step - loss: 0.0673 - accuracy: 0.9787\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 809us/step - loss: 0.0577 - accuracy: 0.9815\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 908us/step - loss: 0.0526 - accuracy: 0.9830\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.0480 - accuracy: 0.9839\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 828us/step - loss: 0.0443 - accuracy: 0.9854\n",
      "313/313 - 0s - loss: 0.0699 - accuracy: 0.9797 - 195ms/epoch - 624us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0699368268251419, 0.9797000288963318]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:02:28.704009Z",
     "start_time": "2024-11-30T12:02:28.687819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "모델이 확률을 반환하도록 하려면 다음과 같이 훈련된 모델을 래핑하고 여기에 소프트맥스를 첨부할 수 있습니다.\n",
    "\"\"\"\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ],
   "id": "e55b9cbc9d606bf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:02:30.107953Z",
     "start_time": "2024-11-30T12:02:30.099181Z"
    }
   },
   "cell_type": "code",
   "source": "probability_model(x_test[:5])",
   "id": "f461c43ec9f0e1db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.08533732, 0.08533732, 0.08533733, 0.08534115, 0.08533732,\n",
       "        0.08533732, 0.08533732, 0.23196018, 0.08533733, 0.08533739],\n",
       "       [0.08533683, 0.08533698, 0.23196772, 0.08533737, 0.08533683,\n",
       "        0.08533683, 0.08533683, 0.08533683, 0.08533683, 0.08533683],\n",
       "       [0.08533856, 0.2319404 , 0.08533911, 0.08533859, 0.08533892,\n",
       "        0.08533859, 0.08533873, 0.08534519, 0.08534331, 0.08533856],\n",
       "       [0.23196739, 0.08533686, 0.08533695, 0.08533686, 0.08533686,\n",
       "        0.08533689, 0.08533701, 0.08533693, 0.08533686, 0.0853374 ],\n",
       "       [0.08546922, 0.08546907, 0.08546908, 0.08546907, 0.22986065,\n",
       "        0.08546907, 0.0854691 , 0.08547482, 0.08546908, 0.08638087]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a26b581b9f996656"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
